\chapter{Introduction}
\label{cha:introduction}

\section{Thesis Objectives}
There are two main objectives in these thesis as the title suggests. First is to distribute the workflow and eliminate central brokers.
Second is minimizing the amount of transferred data in the network. 

Both of these objectives are tailored toward the context that this work is done. There are existing workflow management tools
and data transfer solutions out there but this work is 

This data belongs to operations which might be linear or non-linear
and might involve other operations as well. Each operation can be initiated in any participating
peer but the required data is not necessarily available on that computer even though
the operation result might be delivered back to the same peer.
We will focus on two important topics in this work. First one is data transfer problems between multiple 
computers which are doing a task collaboratively. Second one is the collaboration itself, 
i.e. how multiple computers will manage to finish the task in a distributed and decentralized environment.
To accomplish these objectives we will discuss our specific distributed workflow management and data transfer methods. 
We define our requirements regarding the above mentioned topics and we will extract the parameters which we are going
to assess other solutions with them. Then we will go through the currently available solutions and we will discuss them shortly to see
whether they are applicable to our problem domain with regard to our requirements.

\section{Terminology}
We will use a number of terms through this report. Here are the meaning for each.
\subparagraph{Node}
Refers to one computer in the network.
\subparagraph{Dataset}
We mean both consumed and produced data of scientific applications .e.g. NumPy arrays or HDF5 datasets.
\subparagraph{Application}
The prototype which has been developed to show case the proposed solution, see \ref{cha:prototype}.
\subparagraph{Instance}
An instance of the application running on a node.
\subparagraph{Peer}
One instance of the network application which is in collaboration with other local or remote instances.
\subparagraph{Operation}
Some functions, carrying logic of our application, which users want to run on datasets.
\subparagraph{Task}
Same as the operation with more emphasize on the output rather than the functionality.
\subparagraph{Service}
Remote procedures provided by the application which could be called remotely.
\subparagraph{System}
The combination of nodes, datasets, application, instances, operations and services as a whole.
\subparagraph{User}
A scientist, researcher or student who uses the system.

\section{Problem Context}
Whole this work is an effort to address issues of a scientific environment. Some particular characteristics
are running multiple scientific programs on different computers which need to exchange data in order to
accomplish one operation. Another task which is often done is visualization. Visualizing the operation results
,depending on the requested visualization, might require heavy computational tasks i.e. average or comparison
on data which might not be available on the same machine or might be residing partially on different computers.
The produced data often exceeds 1 GB in many experiments and it should be moved back and forth every few minutes,
therefore it is cheaper to transfer the operation rather than the data.

The problem here is not about distributing the stored data rather exchanging it between instances of the application 
talking together in runtime while doing one global task and keeping this workflow distributed. In this terms each
application instance takes care of its own data and provides a set of services. Some operations require data from
another node, therefore we have to transfer the data or run the operation on the node which contains the data. There
are a number of scenarios which we will discuss.

\section{Document Structure}
This document is organized into \arabic{chapter_count} chapters. 