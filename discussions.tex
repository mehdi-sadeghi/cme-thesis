\chapter{Discussion and Outlook}
\label{cha:discussions}

\section{Data Transfer}
In current design we store files on a random temp folder for each peer.
But we can take advantage of existing Distributed File Systems (DFS).
We can then eliminate the complexity of data transfer among peers. 
DFS has not been considered in our current design but it is an essential part of 
distributed applications.

Currently we store result datasets randomly between peers as there is no
network accessible storage.
We also delegate operations to the peers which contain the data, 
but the data could be availabe via a shared storage.
This will make the whole effort meaningless, 
or it could be better to say that we focus on situations that
machines containg the data do not have access to shared storages.
Again another possibility comes to mind, 
we could make a shared cloud or use a cloud storage provider to 
share data amoung our peers.

These assumptions somehow contradict with our initial requirement,
where we having large datasets spread on multiple machines (and not on a shared storage accessible by all of them). 
We can also consider the price of accessing such data on shared storages and
compare it with having faster local storages and transferring only necessary parts for each operation.
Even though these data could be moved to a cloud but this is not the case for us.

The only improvement that I can think of here, 
is changing the storage strategy and use a cloud storage to keep the results
(one advantage of having a flexible design is right here, 
where we can change our storage strategy with a change in configuration file).
This will let us to avoid the expense of transfering datasets back and forth
between our peers and we would enjoy the simplicity of having one \textit{meta-disk}
to work with. 
We don't rely on DFS in our desgin, we make the decision 
on which node we have to run the operation and when it comes to 
data transfer part we can use a \textit{universal disk} concept to deliver the
remaining data.

\subsection{Large Dataset Transfer}
To transfer large arrays over the network there are a number of considerations. 
Should the array be stored locally before transfer?
What if the array is so big that it does not fit into the machines memory? 
And how the array should be transferred?

Currently we assume the result dataset to fit into the memory, 
therefore there is only the question of how to transfer them over the network. 
To prevent unnecessary copies, we consider streams to send them to other peers. 
In the demo application this is done with streaming sockets. 
The other peer will be notified and then it will fetch the desired dataset.

We need to develop a mechanism to consider dataset size for transfer. 
User defined files are normally small and we can safely transfer them but
system datasets are large and for any transfer some sort of control should happen.

\section{Possible Issues}
\subsection{High Load}
\subsection{Orphan Operations}
\subsection{Complexity Growth}

\section{Future Work}
During this work we have focused on the aspects of the problem which were important in the context 
domain and we left aside many other small and big problems without considering them during this project. The main
reason was that we wanted to work on problems which were new and genuine
because for other aspects there are already many well-defined solutions
available, so we did not spend our time for them. Moreover one should 
consider that this project is not solely an implementation but is a 
research on finding ways to embed distributed solutions into other projects.

In the following sections we talk shortly about the topics which we have
not covered but this work can be extended to include them as well.

\subsection{Non-linear Operations}
The main part which have not been covered yet is non-linear operations.


\subsection{Network Discovery}
Currently the peers are configured in the beginning and there is no dynamic peer recognition. This might be done in a number of ways
such as sending broadcasts or using third party projects such as Zyre \footnote{\url{https://github.com/zeromq/zyre}}

At this stage there is no network discovery, because it is not our main problem. It can be done later as an improvement.

\subsection{Bootstrapping}
With having address of only one peer we would be able to configure and a new peer and join the network. There should be a mechanism among
peers to identify joining and leaving peers. But our context is different than a peer-to-peer applications which peers join and leave 
frequently. In our case most of peers run a long time and bootstrapping is more a way to get the state of currently running workflows and
let others know about the new peer.

\subsection{Data Popularity}
There are algorithms developed to calculate data popularity over time and then replicate them over peers for easier access. If we want to 
move toward any type of data replication we would need to use this algorithms.

\subsection{Security}
There is no user management and secure communication in our initial requirements however this would be required if we want to manage user
rights or introduce limitations or simply to keep a history of activities for each user. Moreover to secure inter-peer communications 
we might use X.509 certificates. Further more since we've used ZeroMQ as underlying transport channel we can use its more advanced
security features such as Elliptic curve cryptography\cite{Curve} based on Curve25519\cite{Curve25519} to add perfect forward secrecy, 
arbitrary authentication backends and so on.

\subsection{Fault Tolerance}
In current work there is no failure recovery mechanism, since it was not part of the requirements. In case of a failure or exception in any 
collaborating peer not only the failed instance should be able to recover itself into a correct state, moreover the other peers should maintain
a valid state for on-going distributed workflows and keep their internal state up-to-date.

Like other topics in this section this one is not of our interest too.
The point is there are existing solutions for these problems 
and we want to let our application to be able to demonstrate the main problem which would be 
deciding about data transfer routes and distributing the information about currently running operations.

\subsection{Web Monitoring}
Before starting my thesis we have developed a job submission and monitoring web application in order to get to know 
job scheduling backends and the workflow and user requirements. 
We called this tool Sqmpy and it is also open source and available 
on Github\footnote{A Simple Queue Manager \url{https://github.com/mehdisadeghi/sqmpy}}.
We can use Sqmpy project as a monitoring tool for konsensus network.
Providing one peer address it can query the rest of peers and connect or 
subscribe to their news channel. Having this we can always see which nodes are
offline and which ones are online. This also gives us a platform to extend
monitoring and control features to the web. Currently we have made the 
required software platform to achieve this. In the Sqmpy project we can simply maintain realtime connections to the browsers and since
our web framework is written in Python, with minimum cost we can integrate it with konsensus which is written with Python as well.